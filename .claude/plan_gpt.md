0) 먼저 현실 체크: “무료로, 안정적으로, 대량 수집”의 최적 경로
A. 영상 목록/통계(조회수·댓글수 등)는 YouTube Data API v3가 가장 안전하고 무료에 가깝다

기본 일일 쿼터가 10,000 units/day(대부분의 읽기 작업에 충분)라는 게 공식 문서에 명시돼 있어.

채널은 핸들(@chonjang)보다 **채널ID(UCIfadKo7fcwSfgARMTz7xzA)**로 잡는 게 가장 안정적이다.

B. “대본(자막/트랜스크립트)”은 공식 API만으로는 타 채널 영상에 대해 안정적으로 다운로드가 어렵다

YouTube Data API의 captions.download는 OAuth 2.0 인증이 필수라고 공식 가이드에 적혀 있고

실제로 “내가 소유하지 않은 영상”의 캡션 다운로드는 권한 문제(403)가 흔하다(공식 API 흐름상).
➡️ 그래서 대본은 보통

(1) youtube-transcript-api 같은 방식(자막이 공개로 열리는 경우)

(2) yt-dlp로 자막(특히 auto-subs)만 추출
중 하나로 해결하는 경우가 많아.

중요한 포인트: 이 부분은 YouTube ToS/저작권/재배포 이슈가 생길 수 있어. “내부 분석용 저장”과 “대중 공개/재배포”는 리스크가 달라. 서비스 공개 전엔 최소한 ToS/법무 체크를 권장.

1) “기수(1~29) 전체 에피소드 파악”을 위해 추가로 꼭 필요한 데이터

지금 “상위 50개 인기 영상 대본 다운로드” 수준에서 → “기수별 전체 에피소드 커버리지”로 가려면, 단순 대본만 저장하면 부족해. 아래 메타데이터가 있어야 누락/중복/정렬/핫이슈 추출이 가능해져.

(필수) 영상 단위 메타데이터

video_id (유일키)

channel_id, channel_title (공식 vs 외부 구분)

published_at

title, description

duration

statistics: viewCount, likeCount, commentCount (댓글수는 “화제성”에 직접 유용)

contentDetails: 라이브/쇼츠 여부(쇼츠가 섞이면 분석 품질 흔들림)

조회수/댓글수 기반 “역대급·자극적” 후보를 만들려면 최소한
commentCount / viewCount, views per day 같은 파생 지표가 필요해.

(강추) “기수/회차(에피소드) 매핑”을 위한 보조 데이터

season_number(기수) 추출 근거:

(1순위) 플레이리스트 기반(“나는 솔로 10기” 같은 playlist)

(2순위) 제목/설명 regex(“10기”, “10기_”, “나는 SOLO 10기” 등)

episode_number(회차) 추출 근거(가능하면):

제목에 “n화/nn회/EPxx”가 있으면 파싱

없으면 업로드 시점 기준 클러스터링(예: 같은 주/방영일 근처 업로드 묶음)

(분석 고도화용) 화제성/자극성 신호(예시)

Engagement score (무료로 가능)

commentCount / viewCount

likeCount / viewCount

views_per_day = viewCount / days_since_published

대본 기반 키워드 신호(저비용)

“빌런/소름/싸움/눈물/역대급/충격/최종선택/삼각관계/오열…” 같은 키워드 빈도

(가능하면) 댓글 상위 N개만 수집해서 “빌런/논란” 판별 보강

다만 댓글 전체 수집은 비용(쿼터/시간)이 커서, “상위 N개 + 댓글수 지표”로 절충 추천

2) 수집 전략(요구사항 1~2 충족): “공식 채널 우선 → 부족 시 일반 검색”
Step A. 공식 채널(@chonjang)에서 “기수별 영상 목록”을 최대한 정확하게 확보

채널의 플레이리스트 목록을 먼저 긁기

“나는 솔로 1기 … 29기” 플레이리스트가 존재할 가능성이 높고(실제로 일부 기수 playlist URL이 확인됨)

플레이리스트 기반이면 정렬(시간순) + 중복 방지가 훨씬 쉬워짐

플레이리스트가 없는 기수는 “채널 업로드 전체”에서 필터링

채널 업로드 목록을 가져오고(uploads playlist / API)

title/description에서 (\d{1,2})기 매칭

“나솔사계/지볶행/미방분” 등 스핀오프가 섞이면 series_type으로 분리 저장

Step B. 공식 채널에서 특정 기수 커버리지가 부족하면 “일반 검색”으로 보완 (하지만 오염 방지 장치 필수)

일반 검색은 리뷰/리액션/짤영상이 섞이는 게 기본이니까, 바로 저장하지 말고 “검수 큐”를 둬야 함.

일반 검색 후보를 가져오되,

title/description에 반드시 “나는 SOLO” + “10기” 같은 강제 조건

채널 화이트리스트/블랙리스트 룰

길이(예: 10초 쇼츠 제외), 업로드 출처 등 필터

그 다음 UI에서 “외부 영상 후보 승인/거절”을 거쳐서만 raw에 들어가게

3) “무료 + 레이트리밋 준수” 설계 포인트
A. Data API 쿼터/호출 구조를 “배치 + 캐시 + 재시도”로

YouTube Data API는 쿼터 기반(기본 10,000 units/day)

구현 팁:

videos.list는 최대 50개 ID를 한 번에 통계 가져오기(배치)

이미 저장된 video_id는 재호출 스킵(ETag/updatedAt로 캐시)

실패(429/5xx)는 exponential backoff + “다음날 재시도 큐”로 넘기기

B. 대본 수집도 “잡 큐 + 초당 요청 제한 + 체크포인트”

시즌 단위/영상 단위로 job을 쪼개고

concurrency=1~3 정도의 느린 병렬 + 랜덤 지터

중간에 끊겨도 resume 가능하게 체크포인트 저장

4) 중복 방지 & 시간순 정렬 로직 (요구사항 3-1 핵심)

“중복”을 두 종류로 나눠서 막아야 해.

(1) 수집 파이프라인 중복 (같은 영상을 여러 번 발견)

DB에 video_id UNIQUE

“발견 단계”에서 이미 있는 video_id면 스킵

시즌 매핑이 바뀌면(예: 일반검색에서 찾았는데 나중에 공식 playlist로 들어옴)
→ season_assignment_history를 남기고 최신 규칙으로 재할당

(2) 콘텐츠 중복 (같은 장면 재업/재편집)

요건 선택사항이지만, 나중에 분석 품질이 확 좋아져.

normalized_transcript_hash(공백/특수문자 제거 후 해시) + duration_bucket으로 “거의 같은 영상”을 군집화

UI에서 “중복 후보”로 표시하고 하나만 대표로 채택하는 옵션 제공

시간순 정렬 우선순위

플레이리스트 내 position (가장 신뢰)

published_at

같은 날 다수면 video_id 안정 정렬

5) UI 3탭을 “작업 도구”로 만드는 구체 스펙 (요구사항 3)
탭 1) 수집(Collector)

필수 UI 컴포넌트

기수 선택:

단일(예: 3기) + 범위(1~5기) + 멀티선택

토글:

“공식 채널만”

“공식 부족 시 일반 검색으로 보완(외부 후보 검수 필요)”

시작 버튼

진행 로그(중요 이벤트만):

“10기 playlist 발견 / 영상 32개”

“메타데이터 저장 완료”

“대본 18/32 완료 (실패 2: 자막 없음)”

완료 팝업:

수집 성공/실패/누락 요약

“Raw 데이터 탭에서 확인하기” 버튼

반복 검증 루프를 위한 기능

“Dry-run(목록만 수집)” 모드: 대본까지 안 가고 video list만 만들기

“Force re-run” 옵션: 규칙 바꿨을 때 재수집

“커버리지 리포트”:

선택한 기수별 수집 영상 수, 대본 성공률, 누락 이유(자막없음/차단/삭제)

탭 2) Raw Data (대본 가시성)

핵심 목표: “대본이 부정확해도, 사람이 빠르게 훑고 검증 가능”해야 함

좌측: 기수/회차/영상 리스트(필터/검색)

중앙: 선택 영상의 transcript 뷰어

타임스탬프 + 문장 단위(또는 10~20초 chunk)

키워드 하이라이트(“빌런/싸움/오열/선택”)

상단 KPI: 조회수/댓글수/업로드일/대본 성공여부

Export:

JSONL / CSV / “분석 탭 인덱싱” 버튼

탭 3) 분석(Analysis Chat + 저장된 뷰)

요구한 “좌측 바(예: 빌런 에피소드)”를 제대로 하려면,
분석 결과를 ‘채팅 로그’가 아니라 ‘저장된 뷰(View)’로 모델링해야 해.

좌측 사이드바: Saved Views

“빌런 에피소드”

“역대급 화제”

“눈물/감동”

“삼각관계”

각 View 클릭 시:

상단 필터: 기수(10기, 11기 체크박스)

본문: 기수별 에피소드(클러스터) 리스트 + 요약 카드

카드 내부: 근거(댓글수/댓글비율/대본 키워드/대표 발언)

예시 구현 흐름 (네가 준 요구)

사용자가: “10기~11기 빌런 에피소드만 모아줘”

시스템이 View를 생성:

view_type = villain

seasons = [10,11]

generated_at

결과는 episode_clusters[] (각 클러스터에 대표 영상 + 근거 점수 + 요약)

6) Codex가 구현하려면 “추가로 확정돼야 하는 것들”(결정/정의 리스트)

Codex는 “정의가 안 된 영역”에서 흔히 삐끗해. 아래를 미리 명시하면 구현 성공률이 확 올라가.

DB 스키마(최소 테이블)

videos (video_id unique)

transcripts (video_id fk, segments json, language, source, success/fail reason)

season_mappings (video_id → season, episode_cluster_id, confidence, evidence)

jobs / job_logs (수집 진행/재시도/체크포인트)

analysis_views / analysis_view_items (좌측 바에 쌓이는 결과)

“에피소드(회차)”의 정의

“기수 내 공식 방송 회차”를 의미하는지,

“유튜브에 업로드된 클립 묶음(업로드 주차 기준)”을 의미하는지
→ 이걸 정해야 ‘10기 5화 빌런’ 같은 UX가 안정적으로 나와.

스핀오프 처리

채널에 “나는 솔로 그 후, 사랑은 계속된다/나솔사계…”가 섞여 있음(쇼츠 제목에서도 보임)
→ 메인(1~29기)과 섞어 저장할지, 분리할지 결정 필요.

외부 검색 시 “오염 방지 정책”

화이트리스트 기반인지, 스코어링 후 수동 승인인지
(추천: 수동 승인 큐)

법/ToS 리스크 범위

내부 분석용(개인/팀)인지

사용자에게 raw transcript를 그대로 공개하는 서비스인지
→ 공개 서비스면 리스크가 급상승.

7) 실행 플랜(반드시 “스크래핑 → Raw 확인 → 규칙 수정” 반복하도록 설계)

아래 순서대로 가면 “중복/누락”이 빨리 잡혀.

Phase 1: Discovery & Metadata (대본 없이)

 채널ID 고정(UCIfadKo7fcwSfgARMTz7xzA)

 플레이리스트 목록 가져오기 → “n기” 매핑 테이블 생성

 선택한 기수의 video_id 리스트를 만들고(정렬 포함)

 videos에 upsert + 통계 저장

✅ 이 단계 완료 기준:
Raw 탭에서 “기수별 영상 리스트가 시간순으로 안정적으로 보임(중복 0)”

Phase 2: Transcript Fetch (실패 케이스 분류가 핵심)

 video_id별 transcript 시도(우선순위: 사람이 UI에서 transcript 열 수 있는 경우 → auto-subs)

 성공/실패 reason 저장:

no_transcript

region_restricted

removed/private

rate_limited

 재시도 정책(다음날/일주일 후) 정의

✅ 완료 기준:
기수별 “대본 성공률”과 “누락 이유”가 리포트로 보임

Phase 3: Season/Episode 클러스터링 규칙 만들기

 playlist 기반이면 position으로 episode cluster 기본 생성

 없으면 업로드일 기준(예: 7일 윈도우)으로 묶고, 제목 키워드로 보정

✅ 완료 기준:
10기 같은 한 기수를 골랐을 때 “클러스터(=에피소드 묶음)가 사람이 봐도 납득” 수준

Phase 4: 분석 탭(View 시스템) + “빌런” 첫 번째 View

 스코어(댓글비율/키워드 등)로 후보 랭킹

 View 저장/재생성

 기수 필터 + 클러스터 리스트 UI

✅ 완료 기준:
“10~11기 빌런 에피소드” 요청 → 좌측에 View 생성 → 클릭하면 결과 재현